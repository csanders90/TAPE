dataset: cora
device: 0
lm:
  model:
    feat_shrink: 
    name: microsoft/deberta-base
  train:
    att_dropout: 0.1
    batch_size: 9
    cla_dropout: 0.4
    dropout: 0.3
    epochs: 4
    eval_patience: 1
    grad_acc_steps: 1
    lr: 0.001
    use_gpt: False
    warmup_epochs: 0.6
    weight_decay: 0.0
runs: 5
seed: 0
data:
  name: cora
  undirected: True
  include_negatives: True
  val_pct: 0.15
  test_pct: 0.05
  split_labels: True
  device: 0
  split_index: [0.8, 0.15, 0.05]

out_dir: results
metric_best: acc
cfg_dest: ft-deberta.yaml
print: file
accelerator: auto
num_threads: 11

run:
  seed: 0
  num_threads: 11
  multiple_splits: None


train:
  mode: custom
  batch_size: 256
  eval_period: 1
  epochs: 10000
  device: 0
  auto_resume: False